import os
import json
from os.path import join, basename

from SCons.Script import Command

vars = Variables()
vars.Add('out', '', 'output-capture')

##### inputs #######
# TODO: move to a config file

bei_data = '/mnt/disk15/molmicro/working/ngh2/2018-08-08-bei-refset'
refpkg = join(bei_data, 'mkrefpkg/output/bei-hm27/bei-hm27-1.0.refpkg')

capture_data = '/molmicro/working/sara/capture_pipeline_output'
with open('data/infiles.txt') as f:
    infiles = f.read().split()

# known classifications
seq_info = '$input/data/seq_info.csv'

binds = ','.join([bei_data, capture_data])

##### end inputs ###

env = Environment(
    variables=vars,
    SHELL='bash',
    cwd=os.getcwd(),
    binds=binds,
    epa=('singularity run --pwd $cwd -B $cwd,$binds epa.simg'),
    gappa=('singularity run --pwd $cwd -B $cwd,$binds gappa.simg'),
    krona=('singularity run --pwd $cwd -B $cwd,$binds krona.simg'),
    taxit=('singularity exec '
           '--pwd $cwd -B $cwd,$binds '
           '/molmicro/common/singularity/taxtastic-0.8.5-singularity2.4.img '
           'taxit'),
    deenurp_img=('singularity exec '
                 '--pwd $cwd -B $cwd,$binds '
                 '/molmicro/common/singularity/deenurp-v0.2.4-singularity2.4.img'),
    nproc=15,
)

def get_refpkg_contents(refpkg):
    with open(join(refpkg, 'CONTENTS.json')) as jfile:
        files = json.load(jfile)['files']
        return {k: join(refpkg, v) for k, v in files.items()}


refpkg_files = get_refpkg_contents(refpkg)
ref_msa = refpkg_files['aln_fasta']
ref_sto = refpkg_files['aln_sto']
tree = refpkg_files['tree']
tree_stats = refpkg_files['tree_stats']
ref_info = refpkg_files['seq_info']
ref_taxonomy = refpkg_files['taxonomy']
profile = refpkg_files['profile']


## begin analysis

taxon_file = env.Command(
    target='$out/taxonomy.txt',
    source=[ref_taxonomy, ref_info],
    action='$taxit lineage_table $SOURCES --taxonomy-table $TARGET'
)

krona_data = []
for infile in infiles:
    label = basename(infile).replace('_processed.fasta', '')
    e = env.Clone(
        label=label,
        out='$out/$label',
    )

    # downsample
    # downsampled = e.Command(
    #     target='$out/inseqs.fasta',
    #     source=infile,
    #     action='seqmagick convert --head 1000 $SOURCE $TARGET'
    # )

    # remove non-16s reads
    seqs_16s, seqs_not16s, cmsearch_scores = e.Command(
        target=['$out/seqs-16s.fasta',
                '$out/seqs-not16s.fasta',
                '$out/cmsearch_scores.txt'],
        source=[infile, 'data/RRNA_16S_BACTERIA.calibrated.cm'],
        action=('$deenurp_img '
                'bin/cmfilter.py $SOURCES '
                '--outfile ${TARGETS[0]} '
                '--discarded ${TARGETS[1]} '
                '--scores ${TARGETS[2]} '
                '--min-evalue 0.01 '
                '--cpu $nproc '
                '--reverse-complement ')
    )
    Depends(seqs_16s, 'bin/cmfilter.py')

    # align input seqs with cmalign
    query_sto, cmalign_scores = e.Command(
        target=['$out/query.sto', '$out/cmalign.scores'],
        source=[seqs_16s, profile],
        # ncores=args.nproc,
        # timelimit=30,
        # slurm_args = '--mem=130000',
        # slurm_queue=large_queue,
        action=(
            '$deenurp_img '
            'cmalign '
            '--cpu $nproc '
            '--mxsize 8196 '
            '--noprob '
            '--dnaout '
            '-o ${TARGETS[0]} '  # alignment in stockholm format
            '--sfile ${TARGETS[1]} '  # scores
            '${SOURCES[1]} '  # alignment profile
            '${SOURCES[0]} '  # input fasta file
            '| grep -E "^#"'  # limit stdout to commented lines
        ))

    refalign, qalign = e.Command(
        target=['$out/refalign.fasta', '$out/qalign.fasta'],
        source=[ref_sto, query_sto],
        action=('$deenurp_img bin/merge.py $SOURCES $TARGETS')
    )
    Depends(refalign, 'bin/merge.py')

    epa_placements, epa_log = e.Command(
        target=['$out/epa_result.jplace', '$out/epa_info.log'],
        source=[refalign, tree, qalign, tree_stats],
        action=('$epa '
                '--ref-msa ${SOURCES[0]} '
                '--tree ${SOURCES[1]} '
                '--query ${SOURCES[2]} '
                '--model `python bin/get_model_descriptor.py ${SOURCES[3]}` '
                '--outdir $out')
    )

    # names of gappa targets appear to be hard-coded
    labelled_tree, per_pquery_assign, gappa_profile, krona_raw = e.Command(
        target=['$out/labelled_tree', '$out/per_pquery_assign',
                '$out/profile.csv', '$out/krona-${label}-raw'],
        source=[epa_placements, taxon_file],
        action=[('$gappa analyze assign '
                '--krona '
                '--out-dir $out '
                '--jplace-path ${SOURCES[0]} '
                 '--taxon-file ${SOURCES[1]}'),
                'mv $out/krona.profile ${TARGETS[3]}']
    )
    krona_data.append(krona_raw)

    # filtered outputs
    classifications, lineages, krona_filtered = e.Command(
        target=['$out/classifications.csv', '$out/lineages.csv', '$out/krona-${label}-filtered'],
        source=per_pquery_assign,
        action=('bin/get_classifications.py $SOURCE '
                '--classifications ${TARGETS[0]} '
                '--lineages ${TARGETS[1]} '
                '--krona ${TARGETS[2]} '
                '--min-afract 0.5 '
                '--min-total 0.75 '
        )
    )
    Depends(classifications, 'bin/get_classifications.py')
    krona_data.append(krona_filtered)

krona_filtered = env.Command(
    target='$out/krona.html',
    source=krona_data,
    action='$krona -o $TARGET $SOURCES'
)
